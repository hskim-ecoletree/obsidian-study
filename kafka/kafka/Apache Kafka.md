

# 1. 카프카란?

무수히 많은 데이터를 손실이나 중복 처리 없이 (near) real-time 으로 처리하기 하기 위한 플랫폼으로 Java, Scala 로 작성되어 있다. LinkedIn 에서 개발 시작되어, 현재는 아파치 재단의 오픈소스 Apache Kafka 프로젝트로 등록되어 관리되고 있다. 초창기 LinkedIn 에서 카프카를 개발했던 주요 멤버들이 Confluent 라는 회사를 만들었으며, 이 회사에서 카프카 클라우드 서비스를 제공하고 있으며, 카프카 오픈소스에 기여하는 바가 큼.

##  1.1. 분산 이벤트 스트리밍 플랫폼

*  __이벤트:__ 사용자, 센서, 애플리케이션 등에서 생성해내는 데이터 일체
* __이벤트 스트리밍:__ 이벤트들이 발생하는 어떤 소스(들)로 부터 해당 이벤트를 원하는 곳까지 이벤트를 전달하며, 즉각적으로 이벤트 데이터의 변환, 보강, 필터링 등의 작업을 할 수 있는 일종의 파이프라인

## 1.2. 이벤트 스트림 _vs._ 전통적인 데이터 저장소 

** _전통적인 데이터 저장소: 데이터 웨어하우스, 관계형 데이터 베이스, 분산 파일 시스템 등과 같이 데이터를 적재 및 보관하는 장소_

|              | **데이터 저장소** | **이벤트 스트림** | 
| ------------ | ------------ |  ------------ | 
| 데이터 상태 | 휴지 상태 (어딘가에 저장되어) | 스트림 (정해진 파이프라인)을 타고 이동 |
| 데이터의 소비 시점 | 데이터를 원하는 시점에 쿼리 | 이벤트가 발생할 때마다 |
| 데이터 처리 | 저장소에 따라 다르지만 데이터의 가공은 주요 기능이 아니며, 원하는 시점에 쿼리 및 제공되는 API 혹은 다른 서비스와 연계하여 처리 (전처리, 변환, 집계 등) | 데이터 스트림 처리 계층을 통한 데이터 변환, 집계 등의 처리 가능 |


---

# 2. 카프카  핵심 개념

## 2.1. 카프카 주요 컴포넌트

- __프로듀서 (Producers)__ 
	- 하나 이상의 토픽에 데이터를 내보내는(Publish) 역할
	- 카프카 클러스터를 제외한 다른 어떤 시스템과 직접 통신하지 않으며, 해당 데이터를 누가 읽을지도 신경쓰지 않음
- __토픽 (Topics)__
	- 카프카 클러스터 내에서 관련 있는 데이터들이 저장(적재)되는 이름있는 스트림 (또는 채널)
	- 일종의 논리적인 데이터 그룹이며, 관계형 데이터 베이스에서는 테이블에 해당한다고 볼 수 있음
	- 다만, 관계형 데이터베이스의 테이블과는 다르게 스키마를 강제하지 않으며, 원시 바이트들을 저장함
	- 하나의 토픽에는 한 종류의 데이터만 _-비단 스카마만을 의미하는것은 아님-_ 저장할 수도 있지만, 여러 종류의 데이터를 저장할 수도 있음.
- __컨슈머 (Consumers)__
	- 하나 이상의 토픽으로부터 데이터를 하나씩 읽어와 소비(Subscribe)하는 역할
	- 특정 프로듀서와 직접 통신하여 데이터를 가져오거나 받는 방식이 아니라, 구독하고 있는 토픽에 데이터가 들어오기를 기다린다.
	- 여러 컨슈머 프로세스들을 분산시켜 동작하고자 할 때, 컨슈머 그룹으로 묶어서 처리할 수 있다. _(컨슈머 그룹 ID를 동일하게 맞춤)
- __이벤트 (Events)__
	- 프로듀서에서 발행하는 데이터. 즉, 카프카 토픽에 저장되는 데이터 (스트리밍 데이터)
	- record, message, payload 등의 용어로 불리기도 함

## 2.2. 통신 모델 구성도

![Kafka Components](https://docs.cloudera.com/runtime/7.2.17/kafka-overview/images/kafka-partition.png)
[그림 1] 카프카 주요 컴포넌트 구성 및 통신 _(출처 https://docs.cloudera.com/runtime/7.2.17/kafka-overview/topics/kafka-overview-partitions.html)_

__** 카프카 통신 모델의 이점__
- 잘 설계된 분산 시스템으로 수평적 확장(scale out)이 용이하며, 고가용성(High Availability), 내결함성(Fault Tolerance) 을 달성할 수 있음
- 각 시스템들은 다른 시스템에 대해 몰라도 데이터의 생산과 소비가 가능하므로, 의존성이 낮아져 유지 보수가 더 용이해짐.
- 기존의 CS 모델에서 하듯이 통신 계층을 분리하는데 시간을 보낼 필요가 없어짐.
- 비동기 통신으로 컨슈머가 일시적으로 다운되었다가 다시 카프카에 연결되었을 때 마지막 데이터 위치부터 다시 데이터를 읽어서 처리할 수 있음.
- 여러 개의 컨슈머가 하나의 그룹으로 실행되고 있었다면, 실행 중인 다른 컨슈머로 작업을 재분배 가능
- 컨슈머들은 각자 처리 가능한 속도로 데이터를 소비할 수 있으며, 아직 처리되지 않은 데이터는 카프카 저장소에 저장한다. 데이터 처리 속도보다 생산 속도가 빨라서 스트림에 데이터가 많아지게 되면, 컨슈머들에 과도한 부하가 걸리지 않도록 버퍼로 동작함.
- 토픽의 데이터(이벤트)들은 Replay 가 가능하여, 언제든지 스트림을 처음부터 다시 실행할 수 있음.

## 2.3.  토픽과 파티션

![[Pasted image 20231218192002.png]]
[그림 2] 카프카 토픽과 파티션 _(출처 https://kafka.apache.org/documentation/#introduction)_

토픽은 이름이 있는 데이터 스트림으로 어떤 데이터들을 논리적인 구분하는 단위이다. 
그리고 실제 토픽의 이벤트(데이터)는 물리적으로 저장된다. _(참고, [[#a. 카프카에서 스트림 데이터는 어떻게 저장되는가]])_
하지만 카프카는 여러 개의 브로커(node)로 구성되는 클러스터로 작동하기 때문에 토픽의 이벤트는 각각의 브로커에 **파티션**의 형태로 적절하게 분산되어 저장되고 있다.

파티션 내부에는 발행된 이벤트를 순차적으로 저장되어 있으며, 다음 컨슈머가 이벤트를 읽어갈 위치인 오프셋(cursor)을 관리하고 있다.
하나의 파티션 내에서는 이벤트의 순서가 보장되지만 토픽 전체로 봤을 때는 파티션 간의 순서가 보장되지 않는다.

카프카에서 이벤트가 어느 파티션에 저장될 지는 프로듀서(Producer)가 결정한다. 이벤트를 특정 파티션에 할당하는 알고리즘은 프로듀서 설정에 의해 결정되며, 주로 다음과 같은 세 가지 방법 중 하나가 사용된다.

1. __라운드 로빈 (Round Robin):__ 메시지를 발행할 때마다 순서대로 파티션에 할당하는 방식으로 파티션에 메시지를 균등하게 분산시키는 특징을 가짐
2. __키  기반 (key-based):__ 메시지의 키를 해시하여 -_키가 없는 경우, 특정 필드를 해시_- 파티션을 선택하는 방식
   해시 값이 같으면 항상 같은 파티션에 할당되므로, 메시지 간의 순서를 유지할 수 있음
3. 사용자 정의: 프로듀서를 개발할 때 직접 파티션을 지정하여 할당할 수 있음. 이 방식은 특수한 요구사항이나 로직이 필요한 경우에 사용될 수 있음.

** _프로듀서가 어떤 파티션에 메시지를 보낼지 결정하는 방법은 프로듀서의 `ProducerRecord` 객체를 생성할 때 설정 가능._

Java code
```
int partitionNumber = 10; // 전송할 토픽의 파티션 번호
String key = "1"; // 이벤트 키
String message = "hello"; // 이벤트 데이터 (메시지)

var record = new ProducerRecord<String, String>("topic_a", partitionNumber, key, message);

...
```


** 세그먼트 (Segments)

파티션의 데이터는 결국 로그의 형태로 저장되는데 계속 하나의 로그 파일에 데이터를 계속 쓸 경우 성능 이슈가 발생하므로 로그를 일정 개수로 분리하여 관리한다.
이때 일정 개수로 분리된 로그의 단위를 (파일) 세그먼트라 한다.

![Partition log segements](https://docs.cloudera.com/runtime/7.2.17/kafka-overview/images/kafka-partition-log-segments.png)
[그림 3] 파티션의 로그 세그먼트 _(출처 https://docs.cloudera.com/runtime/7.2.17/kafka-overview/topics/kafka-overview-logs-and-log-segments.html)_

## 2.6.  카프카 클러스터

- __ZooKeeper__
	- 분산 협력 서비스 (Distributed Coordination Service)로 Java로 작성됨
	- Apache Hadoop 의 서브 프로젝트로 시작되어 2011년 아파치 탑 프로젝트로 승격됨. 
	- 분산 시스템에서 필요한 동기화, 상태 관리, 구성 관리, 네임스페이스 관리 등의 기능을 수행
	- Apache Hadoop, Apache Mesos 등에서 사용됨
	- 클러스터 내의 컨트롤러, 브로커 관리
		- 리더 선출: 리더 브로커가 클러스터에서 이탈하거나 장애 발생 시, 컨트롤러와 협력하여 새로운 리더 브로커를 선출함
		- 브로커 디스커버리: 새로운 브로커가 클러스터에 참여하거나 이탈하는 경우, 토픽 및 파티션 할당과 같은 클러스터의 데이터 일관성 유지에 필요한 작업 수행
	- 코디네이션: 토픽의 파티션 리더 변경, 브로커 상태 변화 등과 같은 클러스터의 상태를 동기화하고, 일관성을 유지함
	- 토픽 및 파티션 관리: 토픽의 생성, 삭제, 구성 변경과 같은 메타데이터를 관리하고 노드 간의 일관성 유지
	- 세션 및 락 관리: 클라이언트 세션 관리 및 분산 락 기능 제공
	- 카프카 진영에서는 메타데이터를 ZooKeeper를 통해 외부에서 관리함으로 인해 발생하는 데이터 중복 및 불일치, 시스템의 복잡성 증가, 서버나 시스템의 추가 구성 등으로 인한 비용 증가와 같은 문제 때문에 카프카의 확장성에 제한된다는 판단을 내려 자체적으로 Kraft 모드를 개발하게 됨 _(Kraft, 기존의 주키퍼 + 컨트롤러를 대체하는 Raft 합의 프로토콜의 이벤트 기반 변형을 사용하는 Kafka의 새로운 쿼럼 컨트롤러 서비스)_
	  
- __컨트롤러:__ 주키퍼와 협력하여 클러스터 내의 브로커를 감시 및 리더 선출 등의 역할을 수행하며, 메타데이터를 관리함
  
- __브로커__ 
	- 카프카 클러스터 내에서 데이터를 저장하고 처리하는 주체
	- 리더 브로커는 해당 파티션에 데이터를 쓰는 작업을 수행
	- 팔로워 브로커는 해당 파티션에 대한 레플리케이션을 생성하거나 데이터를 동기화
	- 토픽과 파티션의 메타데이터를 관리하고, 데이터의 저장 위치, 오프셋과 관련된 정보를 유지



---
# Appendix

## a. 카프카에서 스트림 데이터는 어떻게 저장되는가

카프카의 커밋 로그는 카프카에서 데이터를 저장하는 기본 데이터 구조입니다. 커밋 로그는 각 파티션에 대해 하나씩 존재하며, 파티션은 하나의 토픽을 구성하는 하위 단위입니다. 커밋 로그는 추가만 가능하고 변경은 불가능한 데이터 스트럭처입니다. 즉, 데이터는 항상 로그 끝에 추가되고 변경되지 않습니다.

커밋 로그는 카프카의 데이터 처리에 중요한 역할을 합니다. 프로듀서가 데이터를 카프카에 저장하면, 데이터는 커밋 로그에 추가됩니다. 컨슈머는 커밋 로그에서 데이터를 읽습니다. 커밋 로그는 데이터의 일관성과 복원력을 보장합니다.

커밋 로그의 구조는 다음과 같습니다.

```
| offset | timestamp | key | value |
```

- offset: 데이터의 위치를 나타내는 정수
- timestamp: 데이터가 생성된 시간
- key: 데이터의 식별자
- value: 데이터의 내용

커밋 로그는 다음과 같은 방식으로 작동합니다.

1. 프로듀서가 데이터를 카프카에 저장합니다.
2. 카프카는 데이터를 커밋 로그에 추가합니다.
3. 컨슈머는 커밋 로그에서 데이터를 읽습니다.

커밋 로그의 주요 기능은 다음과 같습니다.

- 데이터의 일관성 보장: 커밋 로그는 추가만 가능하고 변경이 불가능한 데이터 스트럭처이기 때문에, 데이터의 일관성을 보장할 수 있습니다.
- 복원력 보장: 커밋 로그는 데이터를 영구적으로 저장하기 때문에, 시스템 장애가 발생하더라도 데이터를 복구할 수 있습니다.
- 데이터의 효율적인 처리: 커밋 로그는 데이터를 순차적으로 저장하기 때문에, 데이터의 효율적인 처리가 가능합니다.

카프카의 커밋 로그는 카프카의 기본 데이터 구조로서, 카프카의 데이터 처리에 중요한 역할을 합니다.

---

## b. Kafka APIs

- Admin API: 토픽, 브로커와 같은 카프카 컴포넌트를 관리하는 API 제공
- Producer API: 한 개 이상의 토픽에 데이터를 내보내기 위한 API 제공
- Consumer API: 한 개 이상의 토픽으로부터 데이터를 읽어, 처리하기 위한 API 제공
- Kafka Streams API: 카프카를 기반으로 실시간 데이터 스트리밍 처리를 위한 API 제공
	- 데이터 스트림 처리 (인입, 처리, 내보내기(저장))
	- 데이터 조인 및 집계
	- 상태가 있는 데이터 처리
	- 시간 기반 처리, windowing
- Kafka Connect API: 외부 서비스와 카프카 클러스터를 연계하는 서비스
	- 예를 들어, PostgreSQL의 어떤 테이블에 레코드가 insert 되면, 해당 데이터가 카프카의 특정 토픽으로 publish 됨.
- ksqlDB: Kafka API로 보기는 힘들지만, Kafka Streams API 와 마찬가지로 카프카 스트림에 대해 SQL 을 활용하여 스트림 처리할 수 있는 서비스.
	- Kafka Streams API는 구현의 자유도가 높아 복잡한 요구사항을 구현하는데 용이하며, ksqlDB는 비교적 간단하게 SQL과 유사한 언어를 활용하여 스트림 처리를 할 수 있음.
	- ksql과 ksqlDB는 조금 다름. ksql -> ksqlDB 바뀌면서 서버의 개념 생김, 기존 ksql 에서는 push query만 제공되었는데 반해 ksqlDB 에서는 pull query도 제공 등